{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRaFjNBjkWLP"
      },
      "source": [
        "### Lnr Project Task 1.1 Gradient Boosted Trees (e.g., XGBoost) + TF-IDF\n",
        "\n",
        "Niklas Dahlbom, ndahlbom@kth.se, ndahlbo@upv.edu.es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bCiZ3-fmlStK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from readerEXIST2025 import EXISTReader\n",
        "import re\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8a0qOw1yX9G"
      },
      "source": [
        "### Read datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQB83Hpvlzco",
        "outputId": "154cd4f5-f07d-4d1b-bc4c-a30a506481ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1       Writing a uni essay in my local pub with a cof...\n",
            "2       @UniversalORL it is 2021 not 1921. I dont appr...\n",
            "5       According to a customer I have plenty of time ...\n",
            "6       So only 'blokes' drink beer? Sorry, but if you...\n",
            "7       New to the shelves this week - looking forward...\n",
            "                              ...                        \n",
            "3255    idk why y’all bitches think having half your a...\n",
            "3256    This has been a part of an experiment with @Wo...\n",
            "3257    \"Take me already\" \"Not yet. You gotta be ready...\n",
            "3258    @clintneedcoffee why do you look like a whore?...\n",
            "3259    ik when mandy says “you look like a whore” i l...\n",
            "Name: text, Length: 2870, dtype: object\n",
            "-------------------\n"
          ]
        }
      ],
      "source": [
        "reader_train = EXISTReader(\"/Users/niklasdahlbom/Documents/Valencia/Lnr/Project/EXIST 2025 Tweets Dataset/training/EXIST2025_training.json\")\n",
        "reader_dev = EXISTReader(\"/Users/niklasdahlbom/Documents/Valencia/Lnr/Project/EXIST 2025 Tweets Dataset/dev/EXIST2025_dev.json\")\n",
        "reader_test = EXISTReader(\"/Users/niklasdahlbom/Documents/Valencia/Lnr/Project/EXIST 2025 Tweets Dataset/test/EXIST2025_test_clean.json\")\n",
        "\n",
        "EnTrainTask1, EnDevTask1 = reader_train.get(lang=\"EN\", subtask=\"1\"), reader_dev.get(lang=\"EN\", subtask=\"1\")\n",
        "SpTrainTask1, SpDevTask1 = reader_train.get(lang=\"ES\", subtask=\"1\"), reader_dev.get(lang=\"ES\", subtask=\"1\")\n",
        "\n",
        "SpTestTask1, EnTestTask1 = reader_test.get(lang=\"ES\", subtask=\"1\", include_ambiguous=True),  reader_test.get(lang=\"EN\", subtask=\"1\", include_ambiguous=True)\n",
        "\n",
        "print(EnTrainTask1[1])\n",
        "print(\"-------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JMr4Dr8yWWN",
        "outputId": "55524002-3cd5-41b3-8b63-df13fe2f3c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NO: 1733\n",
            "YES: 1137\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "label_counts = Counter(EnTrainTask1[2])\n",
        "print(\"NO:\", label_counts[\"NO\"])\n",
        "print(\"YES:\", label_counts[\"YES\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwpywTpSytMt"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zJ6VoJw4yu4_"
      },
      "outputs": [],
      "source": [
        "def clean_text(text_list):\n",
        "    cleaned_corpus = []\n",
        "    for text in text_list:\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"https?://\\S+\", \"\", text)  # Removes URLs\n",
        "        text = re.sub(r\"@\\w+\", \"\", text)          # Removes mentions\n",
        "        text = text.replace(\"#\", \"\")              # Removes Hashtags\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()   # Removes spaces\n",
        "        cleaned_corpus.append(text)\n",
        "    return cleaned_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa1eUWB6AlEF"
      },
      "outputs": [],
      "source": [
        "# Extract tweets and labels from EnTrainTask1 and EnDevTask1\n",
        "train_texts = EnTrainTask1[1]  # list of tweets\n",
        "train_labels = EnTrainTask1[2] # list of labels (\"YES\" or \"NO\")\n",
        "\n",
        "dev_texts = EnDevTask1[1]\n",
        "dev_labels = EnDevTask1[2]\n",
        "\n",
        "# Convert labels to binary (1 for YES, 0 for NO)\n",
        "train_labels_bin = [1 if label == \"YES\" else 0 for label in train_labels]\n",
        "dev_labels_bin = [1 if label == \"YES\" else 0 for label in dev_labels]\n",
        "\n",
        "# Clean the tweets\n",
        "train_texts_clean = clean_text(train_texts)\n",
        "dev_texts_clean = clean_text(dev_texts)\n",
        "test_texts_clean = clean_text(EnTestTask1[1])  # Clean test texts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dp_oaw2Rxed"
      },
      "source": [
        "### Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T58zSkWr609h"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='binary', zero_division=0, pos_label=1\n",
        "    )\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {acc:.3f}\")\n",
        "    print(f\"Binary F1: {f1:.3f}\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall: {recall:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save results to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qxgo8SqX-cV",
        "outputId": "1d3b052e-4e70-436e-ea73-9ab441126a41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:11:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.797\n",
            "Binary F1: 0.747\n",
            "Precision: 0.821\n",
            "Recall: 0.686\n",
            "Saved test predictions to xgb_predictions_task1.csv ✅\n"
          ]
        }
      ],
      "source": [
        "# === Vectorize the tweets ===\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
        "X_train_tfidf = tfidf.fit_transform(train_texts_clean)\n",
        "X_dev_tfidf = tfidf.transform(dev_texts_clean)\n",
        "X_test_tfidf = tfidf.transform(test_texts_clean)\n",
        "\n",
        "# === Train the model ===\n",
        "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_clf.fit(X_train_tfidf, train_labels_bin)\n",
        "\n",
        "# === Evaluate on dev set ===\n",
        "dev_preds_bin = xgb_clf.predict(X_dev_tfidf)\n",
        "compute_metrics(dev_labels_bin, dev_preds_bin)\n",
        "\n",
        "# === Predict on test set ===\n",
        "test_preds_bin = xgb_clf.predict(X_test_tfidf)\n",
        "test_preds_label = [\"YES\" if p == 1 else \"NO\" for p in test_preds_bin]\n",
        "\n",
        "# === Save test predictions to CSV ===\n",
        "submission_test_df = pd.DataFrame({\n",
        "    \"id\": EnTestTask1[0],\n",
        "    \"label\": test_preds_label,\n",
        "    \"test_case\": [\"EXIST2025\"] * len(test_preds_label)\n",
        "})\n",
        "submission_test_df.to_csv(\"xgb_predictions_task1.csv\", index=False)\n",
        "print(\"Saved test predictions to xgb_predictions_task1.csv ✅\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save to json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to xgb_task1_submission.json ✅\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load your CSV results\n",
        "df = pd.read_csv(\"xgb_predictions_task1.csv\")\n",
        "\n",
        "# Create a list of dictionaries in the required format\n",
        "results_json = []\n",
        "for _, row in df.iterrows():\n",
        "    result = {\n",
        "        \"id\": f\"{row['id']}\",  # add prefix 'id_' as required\n",
        "        \"value\": row[\"label\"],    # if you only have hard outputs (YES/NO)\n",
        "        \"test_case\": row[\"test_case\"]\n",
        "    }\n",
        "    results_json.append(result)\n",
        "\n",
        "# Save to JSON file\n",
        "with open(\"xgb_task1_submission.json\", \"w\") as f:\n",
        "    json.dump(results_json, f, indent=2)\n",
        "\n",
        "print(\"Saved to xgb_task1_submission.json ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spanish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract tweets and labels from EnTrainTask1 and EnDevTask1\n",
        "train_texts = SpTrainTask1[1]  # list of tweets\n",
        "train_labels = SpTrainTask1[2] # list of labels (\"YES\" or \"NO\")\n",
        "\n",
        "dev_texts = SpDevTask1[1]\n",
        "dev_labels = SpDevTask1[2]\n",
        "\n",
        "# Convert labels to binary (1 for YES, 0 for NO)\n",
        "train_labels_bin = [1 if label == \"YES\" else 0 for label in train_labels]\n",
        "dev_labels_bin = [1 if label == \"YES\" else 0 for label in dev_labels]\n",
        "\n",
        "# Clean the tweets\n",
        "train_texts_clean = clean_text(train_texts)\n",
        "dev_texts_clean = clean_text(dev_texts)\n",
        "test_texts_clean = clean_text(SpTestTask1[1])  # Clean test texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "spanish_stopwords = [\n",
        "    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las',\n",
        "    'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como',\n",
        "    'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta',\n",
        "    'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta',\n",
        "    'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos',\n",
        "    'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos',\n",
        "    'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro',\n",
        "    'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes',\n",
        "    'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas',\n",
        "    'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus',\n",
        "    'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía',\n",
        "    'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya',\n",
        "    'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras',\n",
        "    'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas',\n",
        "    'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté',\n",
        "    'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará',\n",
        "    'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías',\n",
        "    'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos',\n",
        "    'estabais', 'estaban'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:11:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.755\n",
            "Binary F1: 0.752\n",
            "Precision: 0.816\n",
            "Recall: 0.697\n",
            "Saved test predictions to xgb_predictions_task1_Spanish.csv ✅\n"
          ]
        }
      ],
      "source": [
        "# === Vectorize the tweets ===\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words=spanish_stopwords)\n",
        "X_train_tfidf = tfidf.fit_transform(train_texts_clean)\n",
        "X_dev_tfidf = tfidf.transform(dev_texts_clean)\n",
        "X_test_tfidf = tfidf.transform(test_texts_clean)\n",
        "\n",
        "# === Train the model ===\n",
        "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_clf.fit(X_train_tfidf, train_labels_bin)\n",
        "\n",
        "# === Evaluate on dev set ===\n",
        "dev_preds_bin = xgb_clf.predict(X_dev_tfidf)\n",
        "compute_metrics(dev_labels_bin, dev_preds_bin)\n",
        "\n",
        "# === Predict on test set ===\n",
        "test_preds_bin = xgb_clf.predict(X_test_tfidf)\n",
        "test_preds_label = [\"YES\" if p == 1 else \"NO\" for p in test_preds_bin]\n",
        "\n",
        "# === Save test predictions to CSV ===\n",
        "submission_test_df = pd.DataFrame({\n",
        "    \"id\": SpTestTask1[0],\n",
        "    \"label\": test_preds_label,\n",
        "    \"test_case\": [\"EXIST2025\"] * len(test_preds_label)\n",
        "})\n",
        "submission_test_df.to_csv(\"xgb_predictions_task1_Spanish.csv\", index=False)\n",
        "print(\"Saved test predictions to xgb_predictions_task1_Spanish.csv ✅\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save to json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to xgb_task1_submission_Spanish.json ✅\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load your CSV results\n",
        "df = pd.read_csv(\"xgb_predictions_task1_Spanish.csv\")\n",
        "\n",
        "# Create a list of dictionaries in the required format\n",
        "results_json = []\n",
        "for _, row in df.iterrows():\n",
        "    result = {\n",
        "        \"id\": f\"{row['id']}\",  # add prefix 'id_' as required\n",
        "        \"value\": row[\"label\"],    # if you only have hard outputs (YES/NO)\n",
        "        \"test_case\": row[\"test_case\"]\n",
        "    }\n",
        "    results_json.append(result)\n",
        "\n",
        "# Save to JSON file\n",
        "with open(\"xgb_task1_submission_Spanish.json\", \"w\") as f:\n",
        "    json.dump(results_json, f, indent=2)\n",
        "\n",
        "print(\"Saved to xgb_task1_submission_Spanish.json ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged 978 EN + 1098 ES = 2076 total predictions.\n"
          ]
        }
      ],
      "source": [
        "filename_english = \"xgb_task1_submission.json\"\n",
        "filename_spanish = \"xgb_task1_submission_Spanish.json\"\n",
        "filename_merged = \"xgb_task1_submission_merged.json\"\n",
        "\n",
        "def merge_predictions(filename_english, filename_spanish, filename_merged):\n",
        "    # Load English predictions\n",
        "    with open(filename_english, \"r\", encoding=\"utf-8\") as f_en:\n",
        "        preds_en = json.load(f_en)\n",
        "\n",
        "    # Load Spanish predictions\n",
        "    with open(filename_spanish, \"r\", encoding=\"utf-8\") as f_es:\n",
        "        preds_es = json.load(f_es)\n",
        "\n",
        "    # Merge the two lists\n",
        "    merged_preds = preds_es + preds_en\n",
        "\n",
        "    # Save the combined predictions\n",
        "    with open(filename_merged, \"w\", encoding=\"utf-8\") as f_out:\n",
        "        json.dump(merged_preds, f_out, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Merged {len(preds_en)} EN + {len(preds_es)} ES = {len(merged_preds)} total predictions.\")\n",
        "    \n",
        "    \n",
        "merge_predictions(\n",
        "    filename_english,\n",
        "    filename_spanish,\n",
        "    filename_merged\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
